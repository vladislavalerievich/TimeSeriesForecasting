data_dir: ./data
model_path: ./models
model_name: Univariate_SineWave
continue_training: false
seed: 2025
debugging: false
wandb: false # whether to log to wandb


lr_scheduler: cosine
initial_lr: 0.0001 # 1e-4
learning_rate: 0.0000001 # 1e-7
scaler: custom_robust
adaptive_loss_normalization: false 
gradient_clip_val: 10000

gradient_accumulation_enabled: false
accumulation_steps: 8  # Number of batches to accumulate before updating (effective batch size = batch_size * accumulation_steps)

total_length: 2048 # gistory length + future length


gift_eval_max_context_length: 1024  # Maximum context length for GIFT evaluation (prevents memory issues)
# batch_size: 128 # Not needed when using pregenerated data with batch size 128
num_epochs: 10
num_training_iterations_per_epoch: 20
log_interval: 1

# TimeSeriesModel Configuration
TimeSeriesModel:
  # Core architecture
  embed_size: 128
  token_embed_dim: 256
  num_encoder_layers: 2
  
  # Scaling and preprocessing
  epsilon: 0.001
  scaler_clamp_value: null
  handle_constants: false
  
  # Time features
  time_feature_config:
    use_enhanced_features: true
    use_holiday_features: false
    use_index_features: true
    k_max: 6
    include_seasonality_info: true
  sin_pos_enc: false
  sin_pos_const: 100
  encoding_dropout: 0.0
  
  # Model architecture
  use_gelu: false
  use_input_projection_norm: true
  use_global_residual: false
  linear_sequence_length: 15
  use_dilated_conv: false
  dilated_conv_kernel_size: 5
  dilated_conv_max_dilation: 3
  
  # Encoder configuration
  encoder_config:
    token_embed_dim: 256
    num_heads: 4


range_proportions:
  short: 0.34
  medium: 0.33
  long: 0.33

generator_proportions:
  short:    
    forecast_pfn: 0.00
    gp: 0.50
    kernel: 0.00
    lmc: 0.
    sine_wave: 0.5
  medium:
    forecast_pfn: 0.00
    gp: 0.50
    kernel: 0.00
    lmc: 0.
    sine_wave: 0.5
  long:   
    forecast_pfn: 0.00
    gp: 0.50
    kernel: 0.00
    lmc: 0.
    sine_wave: 0.5
    